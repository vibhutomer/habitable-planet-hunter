import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)


def load_dataset(file_path: str) -> pd.DataFrame:
    """
    Load dataset from CSV file.
    """
    try:
        df = pd.read_csv(file_path)
        print("Dataset loaded successfully.")
        print(f"Dataset Shape: {df.shape}")
        return df
    except FileNotFoundError:
        raise FileNotFoundError("Dataset file not found. Please check the file path.")

def select_features_and_target(df: pd.DataFrame):
    """
    Select required features and generate binary target.
    """

    allowed_features = [
        'P_MASS', 'P_RADIUS', 'P_DENSITY', 'P_GRAVITY', 'P_ESCAPE', 'P_TYPE',
        'P_PERIOD', 'P_SEMI_MAJOR_AXIS', 'P_ECCENTRICITY', 'P_INCLINATION',
        'P_OMEGA', 'P_PERIASTRON', 'P_APASTRON', 'P_IMPACT_PARAMETER', 'P_HILL_SPHERE',
        'S_MASS', 'S_RADIUS', 'S_LUMINOSITY', 'S_TEMPERATURE', 'S_AGE',
        'S_METALLICITY', 'S_LOG_G', 'S_TYPE', 'S_MAG', 'S_DISC', 'S_MAGNETIC_FIELD',
        'S_SNOW_LINE', 'S_TIDAL_LOCK', 'P_DETECTION', 'P_DISTANCE'
    ]

    target_column = 'P_HABITABLE'

    df_selected = df[allowed_features + [target_column]].copy()

    df_selected['Target'] = df_selected[target_column].apply(
        lambda x: 1 if str(x).lower() == 'yes' else 0
    )

    df_selected.drop(columns=[target_column], inplace=True)

    print("\nBinary Target Distribution:")
    print(df_selected['Target'].value_counts())

    return df_selected


def preprocess_features(df: pd.DataFrame):
    """
    Handle missing values, encode categorical columns, and scale numeric data.
    """

    X = df.drop(columns=['Target'])
    y = df['Target']

    categorical_cols = X.select_dtypes(include=['object']).columns
    numerical_cols = X.select_dtypes(include=['number']).columns

    label_encoders = {}
    for col in categorical_cols:
        encoder = LabelEncoder()
        X[col] = encoder.fit_transform(X[col].astype(str))
        label_encoders[col] = encoder

    imputer = SimpleImputer(strategy="mean")
    X_filled = imputer.fit_transform(X)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_filled)

    return X_scaled, y, X.columns

def train_model(X_train, y_train):
    """
    Train Random Forest classifier.
    """
    model = RandomForestClassifier(
        n_estimators=300,
        random_state=RANDOM_SEED,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    return model

def evaluate_model(model, X_test, y_test):
    """
    Evaluate trained model and visualize results.
    """
    predictions = model.predict(X_test)

    accuracy = accuracy_score(y_test, predictions)
    print(f"\nModel Accuracy: {accuracy * 100:.2f}%\n")

    print("Classification Report:\n")
    print(classification_report(y_test, predictions))

    cm = confusion_matrix(y_test, predictions)
    plot_confusion_matrix(cm)


def plot_confusion_matrix(cm):
    """
    Display confusion matrix.
    """
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title('Confusion Matrix')
    plt.show()

def plot_feature_importance(model, feature_names):
    """
    Plot top 10 important features.
    """
    importance_series = pd.Series(
        model.feature_importances_,
        index=feature_names
    ).sort_values(ascending=False)

    plt.figure(figsize=(8, 6))
    importance_series.head(10).plot(kind='barh')
    plt.title('Top 10 Important Features')
    plt.gca().invert_yaxis()
    plt.show()

def main():

    dataset_path = "../data/full_data.csv"

    df = load_dataset(dataset_path)

    df_selected = select_features_and_target(df)

    X, y, feature_names = preprocess_features(df_selected)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=RANDOM_SEED,
        stratify=y
    )

    model = train_model(X_train, y_train)

    evaluate_model(model, X_test, y_test)

    plot_feature_importance(model, feature_names)

if __name__ == "__main__":
    main()
